{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "#引入torch，torchvision库\n",
    "import torch\n",
    "from torchvision import datasets,transforms\n",
    "#datasets是加载图片数据的方法，transforms是图像预处理的方法\n",
    "from torch import nn,optim\n",
    "#nn即neural network，是专门为神经网络设计的模块化接口；optim是优化器\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([  transforms.ToTensor(),  transforms.Normalize((0.1307,),(0.3081,))])\n",
    "#ToTensor（）是将数据转化为Tensor对象，Normalize（）是对数据进行归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST('data', train=True, download=False, transform=transform)\n",
    "testset = datasets.MNIST('data', train=False, download=False, transform=transform)\n",
    "#使用datasets.MNIST（）来分别下载训练数据集和测试数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建LeNet模型\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        #卷积层c1，c3\n",
    "        self.c1 = nn.Conv2d(1,6,(5,5))\n",
    "        self.c3 = nn.Conv2d(6,16,(5,5))\n",
    "        #全连接层fc1，2，3\n",
    "        self.fc1 = nn.Linear(16*4*4,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self,x):\n",
    "    #池化，池化核2x2\n",
    "        x = F.max_pool2d(F.relu(self.c1(x)),(2,2))\n",
    "        x = F.max_pool2d(F.relu(self.c3(x)),(2,2))\n",
    "        x = x.view(-1,self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    def num_flat_features(self,x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *=s\n",
    "        return num_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化LeNet模型\n",
    "CUDA = 0\n",
    "if CUDA:\n",
    "    lenet = LeNet().cuda()\n",
    "else:\n",
    "    lenet = LeNet()\n",
    "    \n",
    "#损失函数为交叉熵函数,优化器为随机梯度下降\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(lenet.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 4, 2, 4])\n",
      "tensor([1, 9, 2, 7])\n"
     ]
    }
   ],
   "source": [
    "#batch_size表示一次加载的数据量，shuffle = True表示遍历不同批次的数据时打乱顺序，num_workers=2表示使用两个子进程加载数据\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,shuffle = True, num_workers=2)\n",
    "for i,data in enumerate(trainloader,0):\n",
    "    inputs,labels = data\n",
    "    print(labels)\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:1,Batch: 1000] Loss: 1.295\n",
      "[Epoch:1,Batch: 2000] Loss: 0.305\n",
      "[Epoch:1,Batch: 3000] Loss: 0.221\n",
      "[Epoch:1,Batch: 4000] Loss: 0.161\n",
      "[Epoch:1,Batch: 5000] Loss: 0.157\n",
      "[Epoch:1,Batch: 6000] Loss: 0.146\n",
      "[Epoch:1,Batch: 7000] Loss: 0.113\n",
      "[Epoch:1,Batch: 8000] Loss: 0.115\n",
      "[Epoch:1,Batch: 9000] Loss: 0.110\n",
      "[Epoch:1,Batch:10000] Loss: 0.112\n",
      "[Epoch:1,Batch:11000] Loss: 0.096\n",
      "[Epoch:1,Batch:12000] Loss: 0.095\n",
      "[Epoch:1,Batch:13000] Loss: 0.090\n",
      "[Epoch:1,Batch:14000] Loss: 0.083\n",
      "[Epoch:1,Batch:15000] Loss: 0.079\n"
     ]
    }
   ],
   "source": [
    "#训练\n",
    "def train(model,criterion,optimizer,epochs=1):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for i,data in enumerate(trainloader,0):\n",
    "            inputs,labels = data\n",
    "            if CUDA:\n",
    "                inputs,labels = inputs.cuda(),labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss+=loss.item()\n",
    "            if i%1000==999:\n",
    "                print('[Epoch:%d,Batch:%5d] Loss: %.3f' % (epoch+1, i+1, running_loss/1000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "train(lenet,criterion,optimizer,epochs =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存训练好的模型，命名model.pkl\n",
    "torch.save(lenet.state_dict(), 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:97 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
     ]
    }
   ],
   "source": [
    "#加载测试集\n",
    "testset = datasets.MNIST('data', train=False, download=True,transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,shuffle=False, num_workers = 2)\n",
    "#测试训练完的模型\n",
    "def test(testloader,model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        if CUDA:\n",
    "            images = images.cuda()\n",
    "             labels = labels.cuda()\n",
    "        outputs = model(images)\n",
    "        _,predicted = torch.max(outputs.data,1)\n",
    "        total +=labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    print('Accuracy:%d %%' % (100*correct/total))\n",
    "\n",
    "lenet.load_state_dict(torch.load('model.pkl'))\n",
    "test(testloader,lenet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -2.8601,  -2.3236,   5.1342,   3.4096,  -1.8630,  -4.5394, -10.1022,\n",
      "          17.1239,  -3.1820,   3.1620]], grad_fn=<AddmmBackward>)\n",
      "tensor([7])\n"
     ]
    }
   ],
   "source": [
    "'''i = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    print(lenet(images))\n",
    "    print(labels)\n",
    "    images = torch.squeeze(images,0)\n",
    "    to_pil_img = transforms.ToPILImage()#tensor 重新转化成图片格式\n",
    "    images = to_pil_img(images)\n",
    "    images.show()\n",
    "    i+=1\n",
    "    if i>=1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "tensor([[-0.9180,  1.2726,  2.1164,  0.8098, -0.8048, -1.5139, -2.6360,  3.2061,\n",
      "         -0.5543,  0.0556]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "#自己手写数字来进行测试\n",
    "#读取训练好的模型\n",
    "lenet = LeNet()\n",
    "lenet.load_state_dict(torch.load('model.pkl'))\n",
    "#输入图片地址来读-取图片。返回torch.tensor\n",
    "def image_loader(image_name):\n",
    "    image = cv2.imread(image_name)#读取图片\n",
    "    #转换图片为灰度图片\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #高斯滤波\n",
    "    gauss_img = cv2.GaussianBlur(gray_image,(5,5),0,0,cv2.BORDER_DEFAULT)\n",
    "    #修改图片大小为28*28像素\n",
    "    image = cv2.resize(gauss_img,(28,28))\n",
    "\n",
    "    for h in range(28):\n",
    "        for w in range(28):\n",
    "            image[h][w] = 255 - image[h][w]\n",
    "    to_pil_img = transforms.ToPILImage()#tensor 重新转化成图片格式\n",
    "    image1 = to_pil_img(image)\n",
    "    image1.show()\n",
    "    #归一化像素数据\n",
    "    image = transform(image)\n",
    "    return torch.unsqueeze(image.to(torch.float),0)\n",
    "\n",
    "\n",
    "image = image_loader('test_9.jpg')\n",
    "print(image.size())\n",
    "print(lenet(image))\n",
    "#tensor 重新转化成图片格式\n",
    "image = torch.squeeze(image,0)\n",
    "to_pil_img = transforms.ToPILImage()#tensor 重新转化成图片格式\n",
    "image = to_pil_img(image)\n",
    "#image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "CUDA = torch.cuda.is_available()\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4])\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [1, 2, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1,2,3,4]).unsqueeze(0)\n",
    "b = torch.tensor([1,2,3,4]).unsqueeze(0)\n",
    "c = torch.cat((a,b),0)\n",
    "print(a.size())\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_0.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;66;03m#读取图片\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('test_0.jpg')#读取图片\n",
    "print(image.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1，2，3三个数字出现的频率分别为0.3252%,0.3369%,0.3379%。\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "epochs = 10000\n",
    "sum1 = 0\n",
    "sum2 = 0\n",
    "sum3 = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    i = random.randrange(1,4)\n",
    "    if i == 1:\n",
    "        sum1 += 1\n",
    "    elif i == 2:\n",
    "        sum2 += 1\n",
    "    else:\n",
    "        sum3 += 1\n",
    "print('1，2，3三个数字出现的频率分别为%.4f%%,%.4f%%,%.4f%%。'%(100*sum1/epochs,100*sum2/epochs,100*sum3/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scales(image_root,scale):\n",
    "    #每次图片缩小的比例定为缩小后的图片面积为原来的一半\n",
    "    scale = scale\n",
    "    with Image.open(r'F:\\PyTorch\\人脸检测识别\\数据集\\CeleA\\Img\\img_align_celeba\\000001.jpg') as img:\n",
    "    copy = img.copy()\n",
    "    print(img.size)\n",
    "\n",
    "def Pnet_Process(image,scales):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 218)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "squeeze = transforms.ToTensor()\n",
    "\n",
    "with Image.open(r'F:\\PyTorch\\人脸检测识别\\数据集\\CeleA\\Img\\img_align_celeba\\000001.jpg') as img:\n",
    "    copy = img.copy()\n",
    "    print(img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
